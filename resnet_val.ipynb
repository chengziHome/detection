{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import os\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solver.py\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "class Solver():\n",
    "    \n",
    "    def __init__(self,net,check_point,trainloader,valloader,criterion,optimizer,\n",
    "                logfile,print_freq,save_name):\n",
    "        if not net:\n",
    "            raise ValueError(\"We need net arch.So the param 'net' cannot be null.\")\n",
    "        \n",
    "        \n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # statistics data\n",
    "        self.net = net\n",
    "        if check_point:\n",
    "            self.load_checkpoint(check_point)\n",
    "        else:\n",
    "            # reset\n",
    "            self.epoch = 0  # base on 1,not 0\n",
    "            self.acc_epoch_train_top1 = []\n",
    "            self.acc_epoch_train_top5 = []\n",
    "            self.acc_epoch_val_top1 = []\n",
    "            self.acc_epoch_val_top5 = []\n",
    "            # loss per itertation\n",
    "            self.loss_history_train = []\n",
    "            self.loss_history_val = []\n",
    "            # loss per epoch\n",
    "            self.loss_epoch_train = []\n",
    "            self.loss_epoch_val = []\n",
    "            \n",
    "            self.best_top1 = 0\n",
    "        \n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.print_freq = print_freq\n",
    "        self.save_name = save_name\n",
    "        # log\n",
    "        self.logger = logging.getLogger(logfile)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        fh = logging.FileHandler(logfile)\n",
    "        formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "        fh.setFormatter(formatter)\n",
    "        self.logger.addHandler(fh)\n",
    "        \n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        \n",
    "        self.logger.info(\"Solver init done...\")\n",
    "    \n",
    "    def load_checkpoint(self,check_point):\n",
    "        data = torch.load(check_point)\n",
    "        self.net.load_state_dict(data[\"state_dict\"])\n",
    "        self.epoch = data[\"epoch\"]\n",
    "        self.acc_epoch_train_top1 = data[\"acc_epoch_train_top1\"]\n",
    "        self.acc_epoch_train_top5 = data[\"acc_epoch_train_top5\"]\n",
    "        self.acc_epoch_val_top1 = data[\"acc_epoch_val_top1\"]\n",
    "        self.acc_epoch_val_top5 = data[\"acc_epoch_val_top5\"]\n",
    "        # loss per itertation\n",
    "        self.loss_history_train = data[\"loss_history_train\"]\n",
    "        self.loss_history_val = data[\"loss_history_val\"]\n",
    "        # loss per epoch\n",
    "        self.loss_epoch_train = data[\"loss_epoch_train\"]\n",
    "        self.loss_epoch_val = data[\"loss_epoch_val\"]\n",
    "        self.best_top1 = data[\"best_top1\"]\n",
    "    \n",
    "    \n",
    "    def train(self,epochs):\n",
    "        self.logger.info(\"begin training from epoch=\"+str(self.epoch+1))\n",
    "        iter_nums = int(math.ceil(len(self.trainloader.dataset)/self.trainloader.batch_size))\n",
    "        self.logger.info(\"There are \"+ str(iter_nums) +\" iterations per epoch.\")\n",
    "        for epoch in range(epochs):\n",
    "            self.net.train()\n",
    "            self.epoch = self.epoch + 1\n",
    "            losses = AverageMeter()\n",
    "            top1 = AverageMeter()\n",
    "            top5 = AverageMeter()          \n",
    "            \n",
    "            \n",
    "            \n",
    "            for i,(inputs,targets) in enumerate(self.trainloader):\n",
    "                \n",
    "#                 targets = targets - 1 #因为我存储的target是1 <= i <= classes_num\n",
    "                inputs = inputs.cuda()\n",
    "                targets = targets.cuda()\n",
    "                \n",
    "                outputs = self.net(inputs)\n",
    "                loss = self.criterion(outputs,targets)\n",
    "             \n",
    "                # measure and record\n",
    "                prec1,prec5 = self.accuracy(outputs,targets,topk=(1,5))\n",
    "                losses.update(loss.item(),inputs.size(0))\n",
    "                top1.update(prec1.item(),inputs.size(0))\n",
    "                top5.update(prec5.item(),inputs.size(0))\n",
    "                self.loss_history_train.append(loss.item())\n",
    "                \n",
    "                \n",
    "                \n",
    "                # BP\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                \n",
    "                if i%self.print_freq == (self.print_freq-1):\n",
    "                    self.logger.info(\n",
    "                        \"[{epoch:2d},{iter:5d}/{num_iter:d}] \"\n",
    "                        \"loss:({loss.val:.5f},{loss.avg:.5f})  \"\n",
    "                        \"Prec@1:({top1.val:6.3f},{top1.avg:6.3f})  \"\n",
    "                        \"Prec@5:({top5.val:6.3f},{top5.avg:6.3f})\".format(\n",
    "                        epoch=self.epoch,iter=i+1,num_iter=iter_nums,\n",
    "                        loss=losses,top1=top1,top5=top5    \n",
    "                        )                     \n",
    "                    )\n",
    "            self.loss_epoch_train.append(losses.avg)\n",
    "            self.acc_epoch_train_top1.append(top1.avg)\n",
    "            self.acc_epoch_train_top5.append(top5.avg)\n",
    "            \n",
    "            self.validate()\n",
    "            \n",
    "            is_best = self.acc_epoch_val_top1[-1] > self.best_top1\n",
    "            self.save_checkpoint(is_best)\n",
    "        \n",
    "        \n",
    "    def validate(self):\n",
    "        self.net.eval()\n",
    "        losses = AverageMeter()\n",
    "        top1 = AverageMeter()\n",
    "        top5 = AverageMeter()\n",
    "        iter_nums = int(math.ceil(len(self.valloader.dataset)/self.valloader.batch_size))\n",
    "\n",
    "        for i,(inputs,targets) in enumerate(self.valloader):\n",
    "#             print(\"iter:\",i)\n",
    "# #             targets = targets - 1\n",
    "#             print(targets)\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            \n",
    "            outputs = self.net(inputs)\n",
    "            loss = self.criterion(outputs,targets)\n",
    "                                 \n",
    "            acc1,acc5 = self.accuracy(outputs,targets,(1,5))\n",
    "            losses.update(loss.item(),inputs.size(0))\n",
    "            top1.update(acc1.item(),inputs.size(0))\n",
    "            top5.update(acc5.item(),inputs.size(0))\n",
    "            self.loss_history_val.append(loss.item())\n",
    "            \n",
    "            \n",
    "            if i%self.print_freq == (self.print_freq-1):\n",
    "                    self.logger.info(\n",
    "                        \"[{epoch:2d},{iter:5d}/{num_iter:d}] \"\n",
    "                        \"loss:({loss.val:.5f},{loss.avg:.5f})  \"\n",
    "                        \"Prec@1:({top1.val:6.3f},{top1.avg:6.3f})  \"\n",
    "                        \"Prec@5:({top5.val:6.3f},{top5.avg:6.3f})\".format(\n",
    "                        epoch=self.epoch,iter=i+1,num_iter=iter_nums,\n",
    "                        loss=losses,top1=top1,top5=top5    \n",
    "                        )                     \n",
    "                    )\n",
    "        self.loss_epoch_val.append(losses.avg)\n",
    "        self.acc_epoch_val_top1.append(top1.avg)\n",
    "        self.acc_epoch_val_top5.append(top5.avg)\n",
    "            \n",
    "        \n",
    "    def accuracy(self,output,target,topk=(1,)):    \n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "        \n",
    "        values,pred_idx = output.topk(maxk,1,True,True)\n",
    "        pred_idx = pred_idx.t()\n",
    "        correct = pred_idx.eq(target.view(1,-1).expand_as(pred_idx))\n",
    "        \n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0)\n",
    "            res.append(correct_k.mul_(100.0/batch_size))\n",
    "        return res\n",
    "        \n",
    "    def save_checkpoint(self,is_best):\n",
    "        filename=os.path.join(\"./models\",self.save_name+\"_\"+str(self.epoch)+\".pth\")\n",
    "        torch.save({\n",
    "            \"epoch\":self.epoch,\n",
    "            \"state_dict\":self.net.state_dict(),\n",
    "            \"acc_epoch_train_top1\":self.acc_epoch_train_top1,\n",
    "            \"acc_epoch_train_top5\":self.acc_epoch_train_top5,\n",
    "            \"acc_epoch_val_top1\":self.acc_epoch_val_top1,\n",
    "            \"acc_epoch_val_top5\":self.acc_epoch_val_top5,\n",
    "            \"loss_history_train\":self.loss_history_train,\n",
    "            \"loss_history_val\":self.loss_history_val,\n",
    "            \"loss_epoch_train\":self.loss_epoch_train,\n",
    "            \"loss_epoch_val\":self.loss_epoch_val,\n",
    "            \"print_freq\":self.print_freq,\n",
    "            \"best_top1\":self.best_top1\n",
    "        },filename)\n",
    "        if is_best:\n",
    "            shutil.copyfile(filename,os.path.join(\"./models\",\"best\"+\"_\"+str(self.epoch)+\".pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/home/jiazhaohe/datasets/imagenet12\"\n",
    "\n",
    "# meta = torch.load(os.path.join(ROOT,\"meta_data.bin\"))\n",
    "# train_samples = meta[\"train_samples\"]\n",
    "# val_samples = meta[\"val_samples\"]\n",
    "\n",
    "val_transform = torchvision.transforms.Compose([\n",
    "                        transforms.Resize(256),\n",
    "                        transforms.CenterCrop(224),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "# trainset = datasets.ImgListDataset(os.path.join(ROOT,\"train\"),transform,train_samples)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset,batch_size=256,\n",
    "#                                           shuffle=True,num_workers=16,drop_last=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valset = torchvision.datasets.ImageFolder(os.path.join(ROOT,\"val\"),val_transform)\n",
    "valloader = torch.utils.data.DataLoader(valset,batch_size=16,\n",
    "                                          shuffle=False,num_workers=16,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "3125\n"
     ]
    }
   ],
   "source": [
    "print(len(valset))\n",
    "print(len(valloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /home/jiazhaohe/.cache/torch/checkpoints/densenet121-a639ec97.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# net = torchvision.models.alexnet(pretrained=True)\n",
    "# net = torchvision.models.resnet18(pretrained=True)\n",
    "# net = torchvision.models.resnet34(pretrained=True)\n",
    "# net = torchvision.models.resnet50(pretrained=True)\n",
    "# net = torchvision.models.resnet101(pretrained=True)\n",
    "# net = torchvision.models.resnet152(pretrained=True)\n",
    "net = torchvision.models.densenet121(pretrained=True)\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = torch.load(\"./models/resnet18/resnet18_59.pth\")\n",
    "# my_trained_net = torchvision.models.resnet18(pretrained=False)\n",
    "# my_trained_net.load_state_dict(data[\"state_dict\"])\n",
    "# my_trained_net = my_trained_net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=0.05,momentum=0.9,weight_decay=5e-4)\n",
    "\n",
    "check_point = \"./models/resnet18/resnet18_59.pth\"\n",
    "\n",
    "mySolver = Solver(net=net,check_point=None,\n",
    "                        trainloader=None,valloader=valloader,\n",
    "                        criterion=criterion,optimizer=optimizer,\n",
    "                        logfile=\"./logs/resnet18_val.log\",\n",
    "                        print_freq=20,\n",
    "                        save_name=\"resnet18_best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySolver.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74.434]\n",
      "[91.972]\n"
     ]
    }
   ],
   "source": [
    "print(mySolver.acc_epoch_val_top1)\n",
    "\n",
    "print(mySolver.acc_epoch_val_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
