{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = torch.load(\"/home/jiazhaohe/datasets/imagenet12/meta.bin\")\n",
    "# print(type(data))\n",
    "# print(type(data[0]))\n",
    "# print(type(data[1]))\n",
    "# print(len(data[0]))\n",
    "# print(len(data[1]))\n",
    "# wnid_to_idx = {key:i+1 for i,(key,val) in enumerate(data[0].items())}\n",
    "# idx_to_wnid = {i+1:key for i,(key,val) in enumerate(data[0].items())}\n",
    "\n",
    "# val_sample_list = list([])\n",
    "# val_root = \"/home/jiazhaohe/datasets/imagenet12/val\"\n",
    "# for i,j,k in os.walk(val_root):\n",
    "#     for i,filename in enumerate(sorted(k)):\n",
    "# #         print(filename)\n",
    "#         val_sample_list.append((filename,int(lines[i].strip('\\n'))))\n",
    "    \n",
    "# train_sample_list = list([])\n",
    "# train_root = \"/home/jiazhaohe/datasets/imagenet12/train\"\n",
    "# wnids = os.listdir(train_root)\n",
    "# for i,wnid in enumerate(wnids):\n",
    "#     print(\"loop:\",i)\n",
    "#     imgs = os.listdir(os.path.join(train_root,wnid))\n",
    "#     for img in imgs:\n",
    "#         path = wnid + \"/\" + img\n",
    "#         train_sample_list.append((path,wnid_to_idx[wnid]))\n",
    "        \n",
    "\n",
    "# meta_data = {\n",
    "#     \"wnid_to_class\":data[0],\n",
    "#     \"wnid_to_idx\":wnid_to_idx,\n",
    "#     \"idx_to_wnid\":idx_to_wnid,\n",
    "#     \"val_samples\":val_sample_list,\n",
    "#     \"train_samples\":train_sample_list\n",
    "# }\n",
    "\n",
    "# torch.save(meta_data,\"/home/jiazhaohe/datasets/imagenet12/meta_data.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meta = torch.load(\"/home/jiazhaohe/datasets/imagenet12/meta_data.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "\n",
    "class ImgListDataSet(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self,root,transform,samples,loader):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.samples = samples\n",
    "        self.loader = loader\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        path,target = self.samples[index]\n",
    "        sample = self.loader(os.path.join(self.root,path))\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        return sample,target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ROOT = \"/home/jiazhaohe/datasets/imagenet12\"\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "trainset = ImgListDataSet(os.path.join(ROOT,\"train\"),\n",
    "                          transform,meta[\"train_samples\"],pil_loader);\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=512,\n",
    "                                          shuffle=True,num_workers=2)\n",
    "\n",
    "\n",
    "valset = ImgListDataSet(os.path.join(ROOT,\"val\"),\n",
    "                          transform,meta[\"val_samples\"],pil_loader);\n",
    "valloader = torch.utils.data.DataLoader(valset,batch_size=128,\n",
    "                                        shuffle=False,num_workers=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.models.alexnet.AlexNet'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = models.alexnet()   \n",
    "# net = net.cuda()\n",
    "\n",
    "\n",
    "net = torch.load(\"./model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9,weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 4.29975\n",
      "[1,    40] loss: 4.24585\n",
      "[1,    60] loss: 4.28865\n",
      "[1,    80] loss: 4.26562\n",
      "[1,   100] loss: 4.26655\n",
      "[1,   120] loss: 4.28148\n",
      "[1,   140] loss: 4.27043\n",
      "[1,   160] loss: 4.31542\n",
      "[1,   180] loss: 4.31769\n",
      "[1,   200] loss: 4.26868\n",
      "[1,   220] loss: 4.23835\n",
      "[1,   240] loss: 4.27590\n",
      "[1,   260] loss: 4.20539\n",
      "[1,   280] loss: 4.28935\n",
      "[1,   300] loss: 4.28312\n",
      "[1,   320] loss: 4.27345\n",
      "[1,   340] loss: 4.23160\n",
      "[1,   360] loss: 4.23783\n",
      "[1,   380] loss: 4.28669\n",
      "[1,   400] loss: 4.29801\n",
      "[1,   420] loss: 4.26796\n",
      "[1,   440] loss: 4.24637\n",
      "[1,   460] loss: 4.29047\n",
      "[1,   480] loss: 4.27266\n",
      "[1,   500] loss: 4.25277\n",
      "[1,   520] loss: 4.26396\n",
      "[1,   540] loss: 4.26811\n",
      "[1,   560] loss: 4.29117\n",
      "[1,   580] loss: 4.22960\n",
      "[1,   600] loss: 4.26844\n",
      "[1,   620] loss: 4.27181\n",
      "[1,   640] loss: 4.28419\n",
      "[1,   660] loss: 4.20958\n",
      "[1,   680] loss: 4.25021\n",
      "[1,   700] loss: 4.21415\n",
      "[1,   720] loss: 4.23701\n",
      "[1,   740] loss: 4.23939\n",
      "[1,   760] loss: 4.20718\n",
      "[1,   780] loss: 4.25024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiazhaohe/anaconda3/envs/python3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:802: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   800] loss: 4.27333\n",
      "[1,   820] loss: 4.22610\n",
      "[1,   840] loss: 4.24706\n",
      "[1,   860] loss: 4.23566\n",
      "[1,   880] loss: 4.21492\n",
      "[1,   900] loss: 4.26135\n",
      "[1,   920] loss: 4.24749\n",
      "[1,   940] loss: 4.21554\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i,(inputs,target) in enumerate(trainloader): \n",
    "        \n",
    "#         print(inputs.shape)\n",
    "#         print(target)\n",
    "        target = target-1\n",
    "#         print(target)\n",
    "        inputs = inputs.cuda()\n",
    "        target = target.cuda()\n",
    "    \n",
    "        outputs = net(inputs)\n",
    "#         print(outputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#         print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiazhaohe/anaconda3/envs/python3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AlexNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/jiazhaohe/anaconda3/envs/python3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/jiazhaohe/anaconda3/envs/python3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/jiazhaohe/anaconda3/envs/python3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/jiazhaohe/anaconda3/envs/python3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/jiazhaohe/anaconda3/envs/python3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/jiazhaohe/anaconda3/envs/python3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/jiazhaohe/anaconda3/envs/python3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net,\"./model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6416779d738b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "top1 = AverageMeter()\n",
    "top5 = AverageMeter()\n",
    "\n",
    "net.eval()\n",
    "\n",
    "for i,(img,label) in enumerate(valloader):\n",
    "    img,label = img.cuda(),label.cuda()\n",
    "    out = net(img)\n",
    "    print(out.shape)\n",
    "    values,pred_idx = out.topk(5,1,True,True)\n",
    "    pred_idx = pred_idx.t()+1\n",
    "#     print(pred_idx[0,:])\n",
    "#     print(label)\n",
    "    correct = pred_idx.eq(label.view(1,-1).expand_as(pred_idx))\n",
    "    res = []\n",
    "    for k in list([1,5]):\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        \n",
    "        res.append(correct_k.mul_(100.0/128))\n",
    "    print(\"iter:\",i,\":\",res[0],\"++\",res[1])\n",
    "\n",
    "#     top1.update(res[0][0],128)\n",
    "#     top5.update(res[1][0],128)\n",
    "    if i==1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3., 5.])\n",
      "tensor([3., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([2,3,5])\n",
    "print(x)\n",
    "print(x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.alexnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs, labels = data\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
